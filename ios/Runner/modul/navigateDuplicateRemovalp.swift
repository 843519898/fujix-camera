import UIKit
import Flutter
import AVFoundation
import MetalPetal
import MetalKit

/// è§†é¢‘å‰ªè¾‘å¯¼èˆªå¤„ç†å™¨ - å¤„ç†Flutteråˆ°åŸç”Ÿé¡µé¢çš„è·³è½¬é€»è¾‘
public class navigateDuplicateRemovalpHandler {

    public static func Removalp(call: FlutterMethodCall, result: @escaping FlutterResult) {
        guard let args = call.arguments as? [String: String],
              let bgPath = args["bgPath"],
              let fgPath = args["fgPath"],
              let outputPath = args["outputPath"] else {
                  result(FlutterError(code: "BAD_ARGS", message: "å‚æ•°é”™è¯¯", details: nil))
          return
        }
        self.pipVideoMetalPetal(bgPath: bgPath, fgPath: fgPath, outputPath: outputPath) { success, finalPath in
          if success, let finalPath = finalPath {
            result(finalPath)
          } else {
            result(FlutterError(code: "PIP_FAILED", message: "åˆæˆå¤±è´¥", details: nil))
          }
        }
    }
    
    // åˆ›å»ºè¿›åº¦æ¡å›¾åƒçš„æ–¹æ³• - é«˜æ•ˆCPUç»˜åˆ¶ç‰ˆæœ¬
    static func createProgressBarImage(progress: Float, size: CGSize) -> MTIImage? {
        // éªŒè¯è¾“å…¥å°ºå¯¸
        guard size.width > 0 && size.height > 0 else {
            print("âŒ æ— æ•ˆçš„ç”»å¸ƒå°ºå¯¸: \(size)")
            return nil
        }
        
        // è¿›åº¦æ¡é…ç½®
        let progressBarHeight: CGFloat = 8.0
        let progressBarMargin: CGFloat = 40.0
        let progressBarY: CGFloat = 30.0  // å°è¯•ä½¿ç”¨å°å€¼è®©è¿›åº¦æ¡åœ¨åº•éƒ¨
        let backgroundWidth = size.width - 2 * progressBarMargin
        
        print("ğŸ“ è¿›åº¦æ¡é…ç½®: Yä½ç½®=\(progressBarY), è§†é¢‘é«˜åº¦=\(size.height), è¿›åº¦æ¡é«˜åº¦=\(progressBarHeight)")
        
        // ä½¿ç”¨æœ€é«˜æ•ˆçš„CPUç»˜åˆ¶
        let colorSpace = CGColorSpaceCreateDeviceRGB()
        let bitmapInfo = CGBitmapInfo(rawValue: CGImageAlphaInfo.premultipliedLast.rawValue)
        
        guard let context = CGContext(
            data: nil,
            width: Int(size.width),
            height: Int(size.height),
            bitsPerComponent: 8,
            bytesPerRow: Int(size.width) * 4,
            space: colorSpace,
            bitmapInfo: bitmapInfo.rawValue
        ) else {
            print("âŒ æ— æ³•åˆ›å»ºç»˜åˆ¶ä¸Šä¸‹æ–‡")
            return nil
        }
        
        // æ¸…é™¤èƒŒæ™¯ä¸ºé€æ˜
        context.clear(CGRect(origin: .zero, size: size))
        
        // ç»˜åˆ¶è¿›åº¦æ¡èƒŒæ™¯
        context.setFillColor(red: 0, green: 0, blue: 0, alpha: 0.6)
        let backgroundRect = CGRect(
            x: progressBarMargin,
            y: progressBarY,
            width: backgroundWidth,
            height: progressBarHeight
        )
        context.fill(backgroundRect)
        
        // ç»˜åˆ¶è¿›åº¦æ¡å‰æ™¯
        if progress > 0 {
            let progressWidth = max(2.0, backgroundWidth * CGFloat(progress))
            context.setFillColor(red: 1, green: 1, blue: 1, alpha: 0.9)
            let progressRect = CGRect(
                x: progressBarMargin,
                y: progressBarY,
                width: progressWidth,
                height: progressBarHeight
            )
            context.fill(progressRect)
        }
        
        // åˆ›å»ºCGImage
        guard let cgImage = context.makeImage() else {
            print("âŒ æ— æ³•åˆ›å»ºCGImage")
            return nil
        }
        
        // è½¬æ¢ä¸ºMTIImage
        let mtiImage = MTIImage(__cgImage: cgImage, options: [.SRGB: false], isOpaque: false)
        return mtiImage
    }
    
    static func pipVideoMetalPetal(bgPath: String, fgPath: String, outputPath: String, completion: @escaping (Bool, String?) -> Void) {
        print("å¼€å§‹MetalPetalè§†é¢‘åˆæˆ")
        print("èƒŒæ™¯è§†é¢‘è·¯å¾„: \(bgPath)")
        print("å‰æ™¯è§†é¢‘è·¯å¾„: \(fgPath)")
        print("è¾“å‡ºè·¯å¾„: \(outputPath)")

        // 1. åˆå§‹åŒ– MetalPetal ä¸Šä¸‹æ–‡
        guard let device = MTLCreateSystemDefaultDevice() else {
          print("âŒ æ— æ³•åˆ›å»ºMetalè®¾å¤‡")
          completion(false, nil)
          return
        }

        let context: MTIContext
        do {
          context = try MTIContext(device: device)
          print("âœ… MetalPetalä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")
        } catch {
          print("âŒ MetalPetalä¸Šä¸‹æ–‡åˆ›å»ºå¤±è´¥: \(error)")
          completion(false, nil)
          return
        }

        // 2. åŠ è½½å‰æ™¯å’ŒèƒŒæ™¯è§†é¢‘
        let foregroundURL = URL(fileURLWithPath: fgPath)
        let backgroundURL = URL(fileURLWithPath: bgPath)
        let foregroundAsset = AVAsset(url: foregroundURL)
        let backgroundAsset = AVAsset(url: backgroundURL)

        print("å‰æ™¯è§†é¢‘æ—¶é•¿: \(foregroundAsset.duration.seconds)ç§’")
        print("èƒŒæ™¯è§†é¢‘æ—¶é•¿: \(backgroundAsset.duration.seconds)ç§’")

        // è·å–è§†é¢‘è½¨é“ä¿¡æ¯
        guard let fgTrack = foregroundAsset.tracks(withMediaType: .video).first,
              let bgTrack = backgroundAsset.tracks(withMediaType: .video).first else {
          print("âŒ æ— æ³•è·å–è§†é¢‘è½¨é“")
          completion(false, nil)
          return
        }

        let fgSize = fgTrack.naturalSize.applying(fgTrack.preferredTransform)
        let bgSize = bgTrack.naturalSize.applying(bgTrack.preferredTransform)
        print("å‰æ™¯è§†é¢‘å°ºå¯¸: \(abs(fgSize.width)) x \(abs(fgSize.height))")
        print("èƒŒæ™¯è§†é¢‘å°ºå¯¸: \(abs(bgSize.width)) x \(abs(bgSize.height))")

        // è®¡ç®—æ€»å¸§æ•°ç”¨äºè¿›åº¦æ¡
        let videoDuration = min(foregroundAsset.duration.seconds, backgroundAsset.duration.seconds)
        let frameRate: Double = 30.0
        let totalFrames = Int(videoDuration * frameRate)
        print("é¢„è®¡æ€»å¸§æ•°: \(totalFrames)")

        // 3. åˆ›å»ºè¾“å‡ºé…ç½®
        let outputSize = CGSize(width: abs(bgSize.width), height: abs(bgSize.height))
        let videoSettings: [String: Any] = [
          AVVideoCodecKey: AVVideoCodecType.h264,
          AVVideoWidthKey: Int(outputSize.width),
          AVVideoHeightKey: Int(outputSize.height),
          AVVideoCompressionPropertiesKey: [
            AVVideoAverageBitRateKey: 5000000
          ]
        ]

        let outputURL = URL(fileURLWithPath: outputPath)

        // åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
        if FileManager.default.fileExists(atPath: outputPath) {
          try? FileManager.default.removeItem(at: outputURL)
          print("åˆ é™¤å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶")
        }

        let writer: AVAssetWriter
        do {
          writer = try AVAssetWriter(outputURL: outputURL, fileType: .mp4)
          print("âœ… AVAssetWriteråˆ›å»ºæˆåŠŸ")
        } catch {
          print("âŒ AVAssetWriteråˆ›å»ºå¤±è´¥: \(error)")
          completion(false, nil)
          return
        }

        let writerInput = AVAssetWriterInput(mediaType: .video, outputSettings: videoSettings)
        writerInput.expectsMediaDataInRealTime = false

        let adaptor = AVAssetWriterInputPixelBufferAdaptor(
          assetWriterInput: writerInput,
          sourcePixelBufferAttributes: [
            kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA),
            kCVPixelBufferWidthKey as String: Int(outputSize.width),
            kCVPixelBufferHeightKey as String: Int(outputSize.height),
            kCVPixelBufferMetalCompatibilityKey as String: true
          ]
        )

        writer.add(writerInput)

        // 4. åˆ›å»ºAVAssetReader
        let foregroundReader: AVAssetReader
        let backgroundReader: AVAssetReader

        do {
          foregroundReader = try AVAssetReader(asset: foregroundAsset)
          backgroundReader = try AVAssetReader(asset: backgroundAsset)
          print("âœ… AVAssetReaderåˆ›å»ºæˆåŠŸ")
        } catch {
          print("âŒ AVAssetReaderåˆ›å»ºå¤±è´¥: \(error)")
          completion(false, nil)
          return
        }

        let pixelFormatSettings = [
          kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA)
        ]

        let fgOutput = AVAssetReaderTrackOutput(track: fgTrack, outputSettings: pixelFormatSettings)
        let bgOutput = AVAssetReaderTrackOutput(track: bgTrack, outputSettings: pixelFormatSettings)

        fgOutput.alwaysCopiesSampleData = false
        bgOutput.alwaysCopiesSampleData = false

        foregroundReader.add(fgOutput)
        backgroundReader.add(bgOutput)

        // 5. å¼€å§‹è¯»å–å’Œå†™å…¥
        guard writer.startWriting() else {
          print("âŒ æ— æ³•å¼€å§‹å†™å…¥: \(writer.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
          completion(false, nil)
          return
        }

        writer.startSession(atSourceTime: .zero)
        print("âœ… å¼€å§‹å†™å…¥ä¼šè¯")

        // å¯åŠ¨è¯»å–å™¨
        guard foregroundReader.startReading() && backgroundReader.startReading() else {
          print("âŒ æ— æ³•å¼€å§‹è¯»å–è§†é¢‘")
          completion(false, nil)
          return
        }
        print("âœ… å¼€å§‹è¯»å–è§†é¢‘")

        var frameCount = 0
        let frameDuration = CMTime(value: 1, timescale: 30) // 30fps

        // åˆ›å»ºä¸²è¡Œé˜Ÿåˆ—ç”¨äºè§†é¢‘å¤„ç†
        let videoProcessingQueue = DispatchQueue(label: "video.processing", qos: .userInitiated)

        // 6. å¤„ç†å¸§çš„å‡½æ•°
        func processNextFrame() {
          videoProcessingQueue.async {
            guard writerInput.isReadyForMoreMediaData else {
              // å¦‚æœwriterè¿˜æ²¡å‡†å¤‡å¥½ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
              DispatchQueue.main.asyncAfter(deadline: .now() + 0.01) {
                processNextFrame()
              }
              return
            }

            // æ£€æŸ¥readerçŠ¶æ€
            guard foregroundReader.status == .reading && backgroundReader.status == .reading else {
              print("âŒ ReaderçŠ¶æ€å¼‚å¸¸ - å‰æ™¯: \(foregroundReader.status.rawValue), èƒŒæ™¯: \(backgroundReader.status.rawValue)")
              if foregroundReader.status == .failed {
                print("âŒ å‰æ™¯readeré”™è¯¯: \(foregroundReader.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
              }
              if backgroundReader.status == .failed {
                print("âŒ èƒŒæ™¯readeré”™è¯¯: \(backgroundReader.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
              }
              DispatchQueue.main.async {
                completion(false, nil)
              }
              return
            }

            autoreleasepool {
              // è¯»å–ä¸‹ä¸€å¸§
              guard let foregroundSample = fgOutput.copyNextSampleBuffer(),
                    let backgroundSample = bgOutput.copyNextSampleBuffer(),
                    let foregroundPixelBuffer = CMSampleBufferGetImageBuffer(foregroundSample),
                    let backgroundPixelBuffer = CMSampleBufferGetImageBuffer(backgroundSample) else {
                print("ğŸ“± å®Œæˆè¯»å–æ‰€æœ‰å¸§ï¼Œæ€»è®¡: \(frameCount)å¸§")
                writerInput.markAsFinished()

                writer.finishWriting {
                  DispatchQueue.main.async {
                    let success = writer.status == .completed
                    if success {
                      print("âœ… è§†é¢‘åˆæˆå®Œæˆï¼è¾“å‡ºè·¯å¾„: \(outputURL.path)")
                    } else {
                      print("âŒ è§†é¢‘åˆæˆå¤±è´¥: \(writer.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
                    }
                    completion(success, success ? outputURL.path : nil)
                  }
                }
                return
              }

              if frameCount % 30 == 0 {
                print("å¤„ç†ç¬¬ \(frameCount) å¸§")
              }

              do {
                // åˆ›å»ºMTIImage
                let foregroundImage = MTIImage(cvPixelBuffer: foregroundPixelBuffer, alphaType: .alphaIsOne)
                let backgroundImage = MTIImage(cvPixelBuffer: backgroundPixelBuffer, alphaType: .alphaIsOne)

                // è°ƒæ•´å‰æ™¯å›¾åƒå°ºå¯¸ä»¥åŒ¹é…èƒŒæ™¯
                let resizedForeground: MTIImage
                if foregroundImage.size != backgroundImage.size {
                  let scaleX = backgroundImage.size.width / foregroundImage.size.width
                  let scaleY = backgroundImage.size.height / foregroundImage.size.height
                  let scale = min(scaleX, scaleY)

                  // ä½¿ç”¨MTITransformFilterè¿›è¡Œç¼©æ”¾
                  let transformFilter = MTITransformFilter()
                  transformFilter.transform = CATransform3DMakeScale(scale, scale, 1.0)
                  transformFilter.inputImage = foregroundImage

                  guard let scaledImage = transformFilter.outputImage else {
                    print("âŒ å›¾åƒç¼©æ”¾å¤±è´¥")
                    return
                  }
                  resizedForeground = scaledImage
                } else {
                  resizedForeground = foregroundImage
                }

                // æ··åˆå›¾åƒï¼ˆç›´æ¥è®¾ç½®å‰æ™¯é€æ˜åº¦ä¸º0.2ï¼‰
                let blendFilter = MTIBlendFilter(blendMode: .normal)
                blendFilter.inputBackgroundImage = backgroundImage
                blendFilter.inputImage = resizedForeground
                blendFilter.intensity = 0.2  // è®¾ç½®å‰æ™¯é€æ˜åº¦ä¸º0.2

                let cropFilter = MTICropFilter()
                cropFilter.inputImage = blendFilter.outputImage
                // è®¡ç®—10%è¾¹ç¼˜çš„åƒç´ å€¼
                let margin = 0.1
                let cropX = outputSize.width * margin
                let cropY = outputSize.height * margin
                let cropWidth = outputSize.width * (1.0 - 2 * margin)
                let cropHeight = outputSize.height * (1.0 - 2 * margin)
                cropFilter.cropRegion = MTICropRegion(bounds: CGRect(x: cropX, y: cropY, width: cropWidth, height: cropHeight), unit: .pixel) // è£å‰ªæ‰10%çš„è¾¹ç¼˜

                guard let croppedImage = cropFilter.outputImage else {
                  print("âŒ å›¾åƒè£å‰ªå¤±è´¥")
                  return
                }

                // æ·»åŠ è¿›åº¦æ¡
                let currentProgress = totalFrames > 0 ? Float(frameCount) / Float(totalFrames) : 0.0
                guard let progressBarImage = createProgressBarImage(progress: currentProgress, size: croppedImage.size) else {
                  print("âŒ åˆ›å»ºè¿›åº¦æ¡å¤±è´¥")
                  return
                }

                // å°†è¿›åº¦æ¡åˆæˆåˆ°å›¾åƒä¸Š
                let progressBlendFilter = MTIBlendFilter(blendMode: .normal)
                progressBlendFilter.inputBackgroundImage = croppedImage
                progressBlendFilter.inputImage = progressBarImage
                progressBlendFilter.intensity = 1.0

                guard let outputImage = progressBlendFilter.outputImage else {
                  print("âŒ è¿›åº¦æ¡åˆæˆå¤±è´¥")
                  return
                }

                // åˆ›å»ºè¾“å‡ºPixelBuffer
                var outputPixelBuffer: CVPixelBuffer?
                let attrs = [
                  kCVPixelBufferCGImageCompatibilityKey: true,
                  kCVPixelBufferCGBitmapContextCompatibilityKey: true,
                  kCVPixelBufferMetalCompatibilityKey: true,
                  kCVPixelBufferWidthKey: Int(outputSize.width),
                  kCVPixelBufferHeightKey: Int(outputSize.height),
                  kCVPixelBufferPixelFormatTypeKey: kCVPixelFormatType_32BGRA
                ] as CFDictionary

                let status = CVPixelBufferCreate(
                  kCFAllocatorDefault,
                  Int(outputSize.width),
                  Int(outputSize.height),
                  kCVPixelFormatType_32BGRA,
                  attrs,
                  &outputPixelBuffer
                )

                guard status == kCVReturnSuccess, let pixelBuffer = outputPixelBuffer else {
                  print("âŒ PixelBufferåˆ›å»ºå¤±è´¥: \(status)")
                  return
                }

                // æ¸²æŸ“åˆ°PixelBuffer
                try context.render(outputImage, to: pixelBuffer)

                // å†™å…¥è§†é¢‘
                let presentationTime = CMTime(value: Int64(frameCount), timescale: 30)
                let success = adaptor.append(pixelBuffer, withPresentationTime: presentationTime)

                if !success {
                  print("âŒ å†™å…¥ç¬¬ \(frameCount) å¸§å¤±è´¥")
                }

                frameCount += 1

              } catch {
                print("âŒ å¤„ç†ç¬¬ \(frameCount) å¸§æ—¶å‡ºé”™: \(error)")
              }

              // å¤„ç†ä¸‹ä¸€å¸§
              DispatchQueue.main.async {
                processNextFrame()
              }
            }
          }
        }

        // å¼€å§‹å¤„ç†ç¬¬ä¸€å¸§
        DispatchQueue.main.async {
          processNextFrame()
        }
      }
}