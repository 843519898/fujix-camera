import UIKit
import Flutter
import GPUImage
import AVFoundation
import MetalPetal
import MetalKit

@main
@objc class AppDelegate: FlutterAppDelegate {
  override func application(
    _ application: UIApplication,
    didFinishLaunchingWithOptions launchOptions: [UIApplication.LaunchOptionsKey: Any]?
  ) -> Bool {
    let controller = window?.rootViewController as! FlutterViewController

    let channel1 = FlutterMethodChannel(name: "com.cx.flutter.native/channel", binaryMessenger: controller.binaryMessenger)
    channel1.setMethodCallHandler { (call, result) in
          if call.method == "navigateToVideoClip" {
            VideoClipNavigationHandler.handleNavigateToVideoClip(call: call, result: result)
          } else if call.method == "navigateDuplicateRemovalp" {
            navigateDuplicateRemovalpHandler.Removalp(call: call, result: result)
          } else {
            result(FlutterMethodNotImplemented)
          }
        }


    let channel = FlutterMethodChannel(name: "gpuimage_pip", binaryMessenger: controller.binaryMessenger)
    channel.setMethodCallHandler { (call, result) in
      if call.method == "pip" {
        guard let args = call.arguments as? [String: String],
              let bgPath = args["bgPath"],
              let fgPath = args["fgPath"],
              let outputPath = args["outputPath"] else {
          result(FlutterError(code: "BAD_ARGS", message: "å‚æ•°é”™è¯¯", details: nil))
          return
        }
        self.pipVideoWithMetalPetal(bgPath: bgPath, fgPath: fgPath, outputPath: outputPath) { success, finalPath in
          if success, let finalPath = finalPath {
            result(finalPath)
          } else {
            result(FlutterError(code: "PIP_FAILED", message: "åˆæˆå¤±è´¥", details: nil))
          }
        }
      } else {
        result(FlutterMethodNotImplemented)
      }
    }
    GeneratedPluginRegistrant.register(with: self)
    return super.application(application, didFinishLaunchingWithOptions: launchOptions)
  }

  // ç”»ä¸­ç”»åˆæˆ
  func pipVideo(bgPath: String, fgPath: String, outputPath: String, completion: @escaping (Bool, String?) -> Void) {
    let bgURL = URL(fileURLWithPath: bgPath)
    let fgURL = URL(fileURLWithPath: fgPath)
    let outputURL = URL(fileURLWithPath: outputPath)
    let backgroundMovie = GPUImageMovie(url: bgURL)
    let frontMovie = GPUImageMovie(url: fgURL)
    backgroundMovie?.playAtActualSpeed = false
    frontMovie?.playAtActualSpeed = false

    // è·å–è§†é¢‘å°ºå¯¸
    let bgAsset = AVAsset(url: bgURL)
    let fgAsset = AVAsset(url: fgURL)
    guard let bgTrack = bgAsset.tracks(withMediaType: .video).first,
          let fgTrack = fgAsset.tracks(withMediaType: .video).first else {
      completion(false, nil)
      return
    }
    let bgSize = bgTrack.naturalSize
    let fgSize = fgTrack.naturalSize
    let scale = bgSize.width / fgSize.width
    let scaledFgHeight = fgSize.height * scale
    let yOffset = (bgSize.height - scaledFgHeight) / 2
    var transform = CGAffineTransform.identity
    transform = transform.scaledBy(x: scale, y: scale)
    transform = transform.translatedBy(x: 0, y: yOffset / scale)
    let transformFilter = GPUImageTransformFilter()
    transformFilter.affineTransform = transform

    let blendFilter = GPUImageAlphaBlendFilter()
    blendFilter.mix = 0.2 // åªéœ€æ”¹è¿™é‡Œ

    frontMovie?.addTarget(transformFilter)
    transformFilter.addTarget(blendFilter)
    backgroundMovie?.addTarget(blendFilter)

    // è¾“å‡ºä¸ºmov
    let tempMovURL = outputURL.deletingPathExtension().appendingPathExtension("mov")
    let movieWriter = GPUImageMovieWriter(movieURL: tempMovURL, size: bgSize)
    blendFilter.addTarget(movieWriter)

    var hasFinished = false

    movieWriter?.completionBlock = {
      if hasFinished { return }
      hasFinished = true
      movieWriter?.finishRecording()
      // åˆæˆåè½¬ç ä¸ºmp4
      self.convertMovToMp4(movUrl: tempMovURL, mp4Url: outputURL) { success in
        completion(success, success ? outputURL.path : nil)
      }
    }
    movieWriter?.failureBlock = { error in
      if hasFinished { return }
      hasFinished = true
      completion(false, nil)
    }

    movieWriter?.startRecording()
    backgroundMovie?.startProcessing()
    frontMovie?.startProcessing()
  }

  // movè½¬mp4ï¼Œä¿è¯video_playerå…¼å®¹
  func convertMovToMp4(movUrl: URL, mp4Url: URL, completion: @escaping (Bool) -> Void) {
    let asset = AVAsset(url: movUrl)
    guard let exportSession = AVAssetExportSession(asset: asset, presetName: AVAssetExportPresetHighestQuality) else {
      completion(false)
      return
    }
    exportSession.outputURL = mp4Url
    exportSession.outputFileType = .mp4
    exportSession.exportAsynchronously {
      completion(exportSession.status == .completed)
    }
  }

  func pipVideoWithMetalPetal(bgPath: String, fgPath: String, outputPath: String, completion: @escaping (Bool, String?) -> Void) {
    print("å¼€å§‹MetalPetalè§†é¢‘åˆæˆ")
    print("èƒŒæ™¯è§†é¢‘è·¯å¾„: \(bgPath)")
    print("å‰æ™¯è§†é¢‘è·¯å¾„: \(fgPath)")
    print("è¾“å‡ºè·¯å¾„: \(outputPath)")
    
    // 1. åˆå§‹åŒ– MetalPetal ä¸Šä¸‹æ–‡
    guard let device = MTLCreateSystemDefaultDevice() else {
      print("âŒ æ— æ³•åˆ›å»ºMetalè®¾å¤‡")
      completion(false, nil)
      return
    }
    
    let context: MTIContext
    do {
      context = try MTIContext(device: device)
      print("âœ… MetalPetalä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")
    } catch {
      print("âŒ MetalPetalä¸Šä¸‹æ–‡åˆ›å»ºå¤±è´¥: \(error)")
      completion(false, nil)
      return
    }
    
    // 2. åŠ è½½å‰æ™¯å’ŒèƒŒæ™¯è§†é¢‘
    let foregroundURL = URL(fileURLWithPath: fgPath)
    let backgroundURL = URL(fileURLWithPath: bgPath)
    let foregroundAsset = AVAsset(url: foregroundURL)
    let backgroundAsset = AVAsset(url: backgroundURL)
    
    print("å‰æ™¯è§†é¢‘æ—¶é•¿: \(foregroundAsset.duration.seconds)ç§’")
    print("èƒŒæ™¯è§†é¢‘æ—¶é•¿: \(backgroundAsset.duration.seconds)ç§’")
    
    // è·å–è§†é¢‘è½¨é“ä¿¡æ¯
    guard let fgTrack = foregroundAsset.tracks(withMediaType: .video).first,
          let bgTrack = backgroundAsset.tracks(withMediaType: .video).first else {
      print("âŒ æ— æ³•è·å–è§†é¢‘è½¨é“")
      completion(false, nil)
      return
    }
    
    let fgSize = fgTrack.naturalSize.applying(fgTrack.preferredTransform)
    let bgSize = bgTrack.naturalSize.applying(bgTrack.preferredTransform)
    print("å‰æ™¯è§†é¢‘å°ºå¯¸: \(abs(fgSize.width)) x \(abs(fgSize.height))")
    print("èƒŒæ™¯è§†é¢‘å°ºå¯¸: \(abs(bgSize.width)) x \(abs(bgSize.height))")
    
    // 3. åˆ›å»ºè¾“å‡ºé…ç½®
    let outputSize = CGSize(width: abs(bgSize.width), height: abs(bgSize.height))
    let videoSettings: [String: Any] = [
      AVVideoCodecKey: AVVideoCodecType.h264,
      AVVideoWidthKey: Int(outputSize.width),
      AVVideoHeightKey: Int(outputSize.height),
      AVVideoCompressionPropertiesKey: [
        AVVideoAverageBitRateKey: 5000000
      ]
    ]
    
    let outputURL = URL(fileURLWithPath: outputPath)
    
    // åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
    if FileManager.default.fileExists(atPath: outputPath) {
      try? FileManager.default.removeItem(at: outputURL)
      print("åˆ é™¤å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶")
    }
    
    let writer: AVAssetWriter
    do {
      writer = try AVAssetWriter(outputURL: outputURL, fileType: .mp4)
      print("âœ… AVAssetWriteråˆ›å»ºæˆåŠŸ")
    } catch {
      print("âŒ AVAssetWriteråˆ›å»ºå¤±è´¥: \(error)")
      completion(false, nil)
      return
    }
    
    let writerInput = AVAssetWriterInput(mediaType: .video, outputSettings: videoSettings)
    writerInput.expectsMediaDataInRealTime = false
    
    let adaptor = AVAssetWriterInputPixelBufferAdaptor(
      assetWriterInput: writerInput,
      sourcePixelBufferAttributes: [
        kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA),
        kCVPixelBufferWidthKey as String: Int(outputSize.width),
        kCVPixelBufferHeightKey as String: Int(outputSize.height),
        kCVPixelBufferMetalCompatibilityKey as String: true
      ]
    )
    
    writer.add(writerInput)
    
    // 4. åˆ›å»ºAVAssetReader
    let foregroundReader: AVAssetReader
    let backgroundReader: AVAssetReader
    
    do {
      foregroundReader = try AVAssetReader(asset: foregroundAsset)
      backgroundReader = try AVAssetReader(asset: backgroundAsset)
      print("âœ… AVAssetReaderåˆ›å»ºæˆåŠŸ")
    } catch {
      print("âŒ AVAssetReaderåˆ›å»ºå¤±è´¥: \(error)")
      completion(false, nil)
      return
    }
    
    let pixelFormatSettings = [
      kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA)
    ]
    
    let fgOutput = AVAssetReaderTrackOutput(track: fgTrack, outputSettings: pixelFormatSettings)
    let bgOutput = AVAssetReaderTrackOutput(track: bgTrack, outputSettings: pixelFormatSettings)
    
    fgOutput.alwaysCopiesSampleData = false
    bgOutput.alwaysCopiesSampleData = false
    
    foregroundReader.add(fgOutput)
    backgroundReader.add(bgOutput)
    
    // 5. å¼€å§‹è¯»å–å’Œå†™å…¥
    guard writer.startWriting() else {
      print("âŒ æ— æ³•å¼€å§‹å†™å…¥: \(writer.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
      completion(false, nil)
      return
    }
    
    writer.startSession(atSourceTime: .zero)
    print("âœ… å¼€å§‹å†™å…¥ä¼šè¯")
    
    // å¯åŠ¨è¯»å–å™¨
    guard foregroundReader.startReading() && backgroundReader.startReading() else {
      print("âŒ æ— æ³•å¼€å§‹è¯»å–è§†é¢‘")
      completion(false, nil)
      return
    }
    print("âœ… å¼€å§‹è¯»å–è§†é¢‘")
    
    var frameCount = 0
    let frameDuration = CMTime(value: 1, timescale: 30) // 30fps
    
    // åˆ›å»ºä¸²è¡Œé˜Ÿåˆ—ç”¨äºè§†é¢‘å¤„ç†
    let videoProcessingQueue = DispatchQueue(label: "video.processing", qos: .userInitiated)
    
    // 6. å¤„ç†å¸§çš„å‡½æ•°
    func processNextFrame() {
      videoProcessingQueue.async {
        guard writerInput.isReadyForMoreMediaData else {
          // å¦‚æœwriterè¿˜æ²¡å‡†å¤‡å¥½ï¼Œç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
          DispatchQueue.main.asyncAfter(deadline: .now() + 0.01) {
            processNextFrame()
          }
          return
        }
        
        // æ£€æŸ¥readerçŠ¶æ€
        guard foregroundReader.status == .reading && backgroundReader.status == .reading else {
          print("âŒ ReaderçŠ¶æ€å¼‚å¸¸ - å‰æ™¯: \(foregroundReader.status.rawValue), èƒŒæ™¯: \(backgroundReader.status.rawValue)")
          if foregroundReader.status == .failed {
            print("âŒ å‰æ™¯readeré”™è¯¯: \(foregroundReader.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
          }
          if backgroundReader.status == .failed {
            print("âŒ èƒŒæ™¯readeré”™è¯¯: \(backgroundReader.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
          }
          DispatchQueue.main.async {
            completion(false, nil)
          }
          return
        }
        
        autoreleasepool {
          // è¯»å–ä¸‹ä¸€å¸§
          guard let foregroundSample = fgOutput.copyNextSampleBuffer(),
                let backgroundSample = bgOutput.copyNextSampleBuffer(),
                let foregroundPixelBuffer = CMSampleBufferGetImageBuffer(foregroundSample),
                let backgroundPixelBuffer = CMSampleBufferGetImageBuffer(backgroundSample) else {
            print("ğŸ“± å®Œæˆè¯»å–æ‰€æœ‰å¸§ï¼Œæ€»è®¡: \(frameCount)å¸§")
            writerInput.markAsFinished()
            
            writer.finishWriting {
              DispatchQueue.main.async {
                let success = writer.status == .completed
                if success {
                  print("âœ… è§†é¢‘åˆæˆå®Œæˆï¼è¾“å‡ºè·¯å¾„: \(outputURL.path)")
                } else {
                  print("âŒ è§†é¢‘åˆæˆå¤±è´¥: \(writer.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
                }
                completion(success, success ? outputURL.path : nil)
              }
            }
            return
          }
          
          if frameCount % 30 == 0 {
            print("å¤„ç†ç¬¬ \(frameCount) å¸§")
          }
          
          do {
            // åˆ›å»ºMTIImage
            let foregroundImage = MTIImage(cvPixelBuffer: foregroundPixelBuffer, alphaType: .alphaIsOne)
            let backgroundImage = MTIImage(cvPixelBuffer: backgroundPixelBuffer, alphaType: .alphaIsOne)
            
            // è°ƒæ•´å‰æ™¯å›¾åƒå°ºå¯¸ä»¥åŒ¹é…èƒŒæ™¯
            let resizedForeground: MTIImage
            if foregroundImage.size != backgroundImage.size {
              let scaleX = backgroundImage.size.width / foregroundImage.size.width
              let scaleY = backgroundImage.size.height / foregroundImage.size.height
              let scale = min(scaleX, scaleY)
              
              // ä½¿ç”¨MTITransformFilterè¿›è¡Œç¼©æ”¾
              let transformFilter = MTITransformFilter()
              transformFilter.transform = CATransform3DMakeScale(scale, scale, 1.0)
              transformFilter.inputImage = foregroundImage
              
              guard let scaledImage = transformFilter.outputImage else {
                print("âŒ å›¾åƒç¼©æ”¾å¤±è´¥")
                return
              }
              resizedForeground = scaledImage
            } else {
              resizedForeground = foregroundImage
            }
            
            // æ··åˆå›¾åƒï¼ˆç›´æ¥è®¾ç½®å‰æ™¯é€æ˜åº¦ä¸º0.2ï¼‰
            let blendFilter = MTIBlendFilter(blendMode: .normal)
            blendFilter.inputBackgroundImage = backgroundImage
            blendFilter.inputImage = resizedForeground
            blendFilter.intensity = 0.2  // è®¾ç½®å‰æ™¯é€æ˜åº¦ä¸º0.2
            
            guard let outputImage = blendFilter.outputImage else {
              print("âŒ å›¾åƒæ··åˆå¤±è´¥")
              return
            }
            
            // åˆ›å»ºè¾“å‡ºPixelBuffer
            var outputPixelBuffer: CVPixelBuffer?
            let attrs = [
              kCVPixelBufferCGImageCompatibilityKey: true,
              kCVPixelBufferCGBitmapContextCompatibilityKey: true,
              kCVPixelBufferMetalCompatibilityKey: true,
              kCVPixelBufferWidthKey: Int(outputSize.width),
              kCVPixelBufferHeightKey: Int(outputSize.height),
              kCVPixelBufferPixelFormatTypeKey: kCVPixelFormatType_32BGRA
            ] as CFDictionary
            
            let status = CVPixelBufferCreate(
              kCFAllocatorDefault,
              Int(outputSize.width),
              Int(outputSize.height),
              kCVPixelFormatType_32BGRA,
              attrs,
              &outputPixelBuffer
            )
            
            guard status == kCVReturnSuccess, let pixelBuffer = outputPixelBuffer else {
              print("âŒ PixelBufferåˆ›å»ºå¤±è´¥: \(status)")
              return
            }
            
            // æ¸²æŸ“åˆ°PixelBuffer
            try context.render(outputImage, to: pixelBuffer)
            
            // å†™å…¥è§†é¢‘
            let presentationTime = CMTime(value: Int64(frameCount), timescale: 30)
            let success = adaptor.append(pixelBuffer, withPresentationTime: presentationTime)
            
            if !success {
              print("âŒ å†™å…¥ç¬¬ \(frameCount) å¸§å¤±è´¥")
            }
            
            frameCount += 1
            
          } catch {
            print("âŒ å¤„ç†ç¬¬ \(frameCount) å¸§æ—¶å‡ºé”™: \(error)")
          }
          
          // å¤„ç†ä¸‹ä¸€å¸§
          DispatchQueue.main.async {
            processNextFrame()
          }
        }
      }
    }
    
    // å¼€å§‹å¤„ç†ç¬¬ä¸€å¸§
    DispatchQueue.main.async {
      processNextFrame()
    }
  }
}